{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7531d5-0c22-49ad-9d37-8b08eec7d4e0",
   "metadata": {},
   "source": [
    "# L4: Process Inputs: Chain of Thought Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd85a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determine the most appropriate course of action based on the teacher's most recent answer via the follwing steps:\n",
      "Step 1: #### Determine if the teacher conveys important information relevant to the student's question; if yes, provide encouragement\n",
      "Step 2: #### Determine if the teacher's response contains incorrect information; if yes, gently point it out\n",
      "Step 3: #### Determine if the teacher does not know the answer; if yes, encourage them to look at the learning material or provide a hint\n",
      "Step 4: #### Determine if the teacher addresses the professor directly for help; if yes, provide relevant information\n",
      "Step 5: #### Determine if the teacher is completely off topic; if yes, ask the teacher to focus on the student's questions\n",
      "Step 6: #### Determine if the teacher response is inappropriate; if yes encourage the teacher to be mindful towards the student\n",
      "\n",
      "Formulate a polite and brief comment for the teacher based on your decision from the previous steps.\n",
      "\n",
      "Use the following format:\n",
      "Step 1:#### <step 1 reasoning>\n",
      "Step 2:#### <step 2 reasoning>\n",
      "Step 3:#### <step 3 reasoning>\n",
      "Step 4:#### <step 4 reasoning>\n",
      "Step 5:#### <step 5 reasoning>\n",
      "Step 6:#### <step 6 reasoning>\n",
      "Response to teacher:#### <response to teacher>\n",
      "\n",
      "Make sure to include #### to separate every step.\n"
     ]
    }
   ],
   "source": [
    "print(\"Determine the most appropriate course of action based on the teacher's most recent answer via the follwing steps:\\nStep 1: #### Determine if the teacher conveys important information relevant to the student's question; if yes, provide encouragement\\nStep 2: #### Determine if the teacher's response contains incorrect information; if yes, gently point it out\\nStep 3: #### Determine if the teacher does not know the answer; if yes, encourage them to look at the learning material or provide a hint\\nStep 4: #### Determine if the teacher addresses the professor directly for help; if yes, provide relevant information\\nStep 5: #### Determine if the teacher is completely off topic; if yes, ask the teacher to focus on the student's questions\\nStep 6: #### Determine if the teacher response is inappropriate; if yes encourage the teacher to be mindful towards the student\\n\\nFormulate a polite and brief comment for the teacher based on your decision from the previous steps.\\n\\nUse the following format:\\nStep 1:#### <step 1 reasoning>\\nStep 2:#### <step 2 reasoning>\\nStep 3:#### <step 3 reasoning>\\nStep 4:#### <step 4 reasoning>\\nStep 5:#### <step 5 reasoning>\\nStep 6:#### <step 6 reasoning>\\nResponse to teacher:#### <response to teacher>\\n\\nMake sure to include #### to separate every step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613f6af-ce1c-49ea-ae99-0d2e3fa3fae1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "#### Load the API key and relevant Python libaries.\n",
    "In this course, we've provided some code that loads the OpenAI API key for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1c9e8",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a05b6",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d273f-df72-47e2-a9a6-a8994d742aec",
   "metadata": {},
   "source": [
    "## Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e66beb-8fb5-4c7b-afa7-13d20ded1d49",
   "metadata": {
    "height": 1543
   },
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "system_message = f\"\"\"\n",
    "Follow these steps to answer the customer queries.\n",
    "The customer query will be delimited with four hashtags,\\\n",
    "i.e. {delimiter}. \n",
    "\n",
    "Step 1:{delimiter} First decide whether the user is \\\n",
    "asking a question about a specific product or products. \\\n",
    "Product cateogry doesn't count. \n",
    "\n",
    "Step 2:{delimiter} If the user is asking about \\\n",
    "specific products, identify whether \\\n",
    "the products are in the following list.\n",
    "All available products: \n",
    "1. Product: TechPro Ultrabook\n",
    "   Category: Computers and Laptops\n",
    "   Brand: TechPro\n",
    "   Model Number: TP-UB100\n",
    "   Warranty: 1 year\n",
    "   Rating: 4.5\n",
    "   Features: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
    "   Description: A sleek and lightweight ultrabook for everyday use.\n",
    "   Price: $799.99\n",
    "\n",
    "2. Product: BlueWave Gaming Laptop\n",
    "   Category: Computers and Laptops\n",
    "   Brand: BlueWave\n",
    "   Model Number: BW-GL200\n",
    "   Warranty: 2 years\n",
    "   Rating: 4.7\n",
    "   Features: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
    "   Description: A high-performance gaming laptop for an immersive experience.\n",
    "   Price: $1199.99\n",
    "\n",
    "Step 3:{delimiter} If the message contains products \\\n",
    "in the list above, list any assumptions that the \\\n",
    "user is making in their \\\n",
    "message e.g. that Laptop X is bigger than \\\n",
    "Laptop Y, or that Laptop Z has a 2 year warranty.\n",
    "\n",
    "Step 4:{delimiter}: If the user made any assumptions, \\\n",
    "figure out whether the assumption is true based on your \\\n",
    "product information. \n",
    "\n",
    "Step 5:{delimiter}: First, politely correct the \\\n",
    "customer's incorrect assumptions if applicable. \\\n",
    "Only mention or reference products in the list of \\\n",
    "5 available products, as these are the only 5 \\\n",
    "products that the store sells. \\\n",
    "Answer the customer in a friendly tone.\n",
    "\n",
    "Use the following format:\n",
    "Step 1:{delimiter} <step 1 reasoning>\n",
    "Step 2:{delimiter} <step 2 reasoning>\n",
    "Step 3:{delimiter} <step 3 reasoning>\n",
    "Step 4:{delimiter} <step 4 reasoning>\n",
    "Response to user:{delimiter} <response to customer>\n",
    "\n",
    "Make sure to include {delimiter} to separate every step.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof workflow\n",
    "# 3. ask user to focus on the student's question if they derail the conversation\n",
    "# 4. User asks for help\n",
    "\n",
    "Do a simple two step prompt:\n",
    "    First classify the users response:\n",
    "    Then react based on classification\n",
    "\n",
    "\n",
    "Do one of the following:\n",
    "    * If the teacher response conveys is contains incorrect information gently correct the user\n",
    "    * \n",
    "\n",
    "# \n",
    "# \n",
    "#\n",
    "# \n",
    "#\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681752f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT KEY INSTRUCTIONS FROM CURRENT PROMPT\n",
    "\n",
    "delimiter = \"####\"\n",
    "\n",
    "PROF_INST = f\"\"\"You are a friendly and encouraging professor who supervises\n",
    "interactions between a new teacher and a 18-year old student. You only provide\n",
    "very brief advice to the teacher and you always keep things positive.\n",
    "\n",
    "The material the teacher needs to explain is delimited by four hashtags and you\n",
    "must not refer to any information that is not explained in the material: \n",
    "\n",
    "Material: {delimiter} eukaryoticCellText {delimiter}\n",
    "\n",
    "Step 1: Determine the most appropriate course of action based on the teacher's most recent answer:\n",
    "    a) If the teacher conveys important information relevent to the student's question provide encouragement\n",
    "    b) If the teacher's response contains incorrect information gently point it out\n",
    "    c) If the teacher does not know the answer encourage them to look at the learning material or provide a hint\n",
    "    d) If the teacher addresses the professor directly for help provide relevant information\n",
    "    e) If the teacher if completly off topic ask the teacher to focus on the student's questions\n",
    "    f) If the teacher response is inappropirate encourage the teacher to be mindful towards the student\n",
    "\n",
    "Step 1:{delimiter} First decide whether the teacher tries to address the \\\n",
    "student's question and wheter. \\\n",
    "\n",
    "Step 2: {delimiter} Formulate a polite and brief comment for the teacher based on your decision from step 1.\n",
    "\n",
    "Use the following format:\n",
    "Step 1:{delimiter} <step 1 reasoning>\n",
    "Response to teacher:{delimiter} <response to teacher>\n",
    "\n",
    "Make sure to include {delimiter} to separate every step.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1ea0a-a816-4694-8a79-77d985f2e274",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "user_message = f\"\"\"\n",
    "by how much is the BlueWave Chromebook more expensive \\\n",
    "than the TechPro Desktop\"\"\"\n",
    "\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},    \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] \n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51afe6d",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "user_message = f\"\"\"\n",
    "do you sell tvs\"\"\"\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},    \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552a4f6-5e65-4d85-9579-5263f720aa10",
   "metadata": {},
   "source": [
    "## Inner Monologue\n",
    "- Since we asked the LLM to separate its reasoning steps by a delimiter, we can hide the chain-of-thought reasoning from the final output that the user sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a825237",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    final_response = response.split(delimiter)[-1].strip()\n",
    "except Exception as e:\n",
    "    final_response = \"Sorry, I'm having trouble right now, please try asking another question.\"\n",
    "    \n",
    "print(final_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
